## PyTorch Vision Transformer (ViT) MNIST classifier

<p align="center">
	<img src="images/data_samples.png"/>
	<br/>
	<img src="images/imgs_to_patches.png"/>
</p>

Test set performance:

<p align="center">
	<img src="images/test_confusion_matrix.png"/>
</p>

Attention heatmaps of first attention block on user-drawn digits:

<p align="center">
	<img src="images/attention_heatmap1.png"/>
	<br/>
	<img src="images/attention_heatmap2.png"/>
</p>

Model architecture:

<p align="center">
	<img src="images/model_architecture.png"/>
</p>

Sources:
- [Vision Transformer (ViT) Attention Maps using MNIST](https://github.com/mashaan14/VisionTransformer-MNIST/tree/main)
- [Quantifying Attention Flow in Transformers](https://arxiv.org/pdf/2005.00928) (Abnar, Zuidema 2020)
